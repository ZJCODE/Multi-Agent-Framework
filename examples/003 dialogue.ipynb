{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from src import Env,Group,Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[93m \n",
      "[2025-01-08 16:01:14][INFO]: All agents are fully connected\u001b[00m\n",
      "\u001b[1m\u001b[93m \n",
      "[2025-01-08 16:01:14][INFO]: Group initialized with ID 69da27a2-aa13-4d81-bfc7-eba5adcbf82e\u001b[00m\n"
     ]
    }
   ],
   "source": [
    "# load the environment variables\n",
    "load_dotenv()\n",
    "# create a model client\n",
    "model_client = OpenAI()\n",
    "# create an environment\n",
    "env = Env(\n",
    "    description=\"On Sunday morning at 7:00 AM, a new day starts. The family of four is assembled in the living room. Tom reads the newspaper, Alice prepares breakfast, Jerry watches TV, and Spike plays with his toy. They start chatting, with each person addressing only one other individual at a time using straightforward language.\",\n",
    "    members=[\n",
    "        Agent(name=\"Tom\", \n",
    "              role=\"Father of the family\",\n",
    "              description=\"He is a software engineer,Alice is his wife, Jerry is his son, Spike is his dog,just spkeck to one person at a time in simple language\",\n",
    "              model_client=model_client,\n",
    "              verbose=True),\n",
    "        Agent(name=\"Alice\",\n",
    "                role=\"Mother of the family\",\n",
    "                description=\"She is a doctor, Tom is her husband, Jerry is her son, Spike is her dog,just spkeck to one person at a time in simple language\",\n",
    "                model_client=model_client, # agent build with a openai model client\n",
    "                verbose=True),\n",
    "        Agent(name=\"Jerry\",\n",
    "              role=\"son of the family\",\n",
    "              description=\"He is a student, Tom is his father, Alice is his mother, Spike is his dog,just spkeck to one person at a time in simple language\",\n",
    "              model_client=model_client, # agent build with a openai model client\n",
    "              verbose=True),\n",
    "        Agent(name=\"Spike\",\n",
    "                role=\"dog of the family\",\n",
    "                description=\"He is a dog, Tom is his owner, Alice is his owner, Jerry is his owner,always say woof woof or bark bark\",\n",
    "                model_client=model_client, # agent build with a openai model client\n",
    "                verbose=True),\n",
    "    ],\n",
    ")\n",
    "# create a group of agents\n",
    "g = Group(env=env,model_client=model_client,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[93m \n",
      "[2025-01-08 16:01:16][INFO]: handoff from Tom to Alice by using auto mode\u001b[00m\n",
      "\u001b[1m\u001b[92m \n",
      "[2025-01-08 16:01:18][INFO]: Calling OpenAI agent [Alice]\u001b[00m\n",
      "\u001b[1m\u001b[95m \n",
      "[2025-01-08 16:01:19][INFO]: Agent Alice response:\n",
      "\n",
      "Good morning, Tom! How is the newspaper today?\u001b[00m\n",
      "\u001b[1m\u001b[93m \n",
      "[2025-01-08 16:01:20][INFO]: handoff from Alice to Tom by using auto mode\u001b[00m\n",
      "\u001b[1m\u001b[92m \n",
      "[2025-01-08 16:01:21][INFO]: Calling OpenAI agent [Tom]\u001b[00m\n",
      "\u001b[1m\u001b[95m \n",
      "[2025-01-08 16:01:23][INFO]: Agent Tom response:\n",
      "\n",
      "Good morning, Alice! The newspaper has some interesting articles today. How's breakfast coming along?\u001b[00m\n",
      "\u001b[1m\u001b[93m \n",
      "[2025-01-08 16:01:24][INFO]: handoff from Tom to Alice by using auto mode\u001b[00m\n",
      "\u001b[1m\u001b[92m \n",
      "[2025-01-08 16:01:25][INFO]: Calling OpenAI agent [Alice]\u001b[00m\n",
      "\u001b[1m\u001b[95m \n",
      "[2025-01-08 16:01:27][INFO]: Agent Alice response:\n",
      "\n",
      "It's going well, Tom! I'm making pancakes and eggs. Do you want coffee with your breakfast?\u001b[00m\n",
      "\u001b[1m\u001b[93m \n",
      "[2025-01-08 16:01:27][INFO]: handoff from Alice to Tom by using auto mode\u001b[00m\n",
      "\u001b[1m\u001b[92m \n",
      "[2025-01-08 16:01:28][INFO]: Calling OpenAI agent [Tom]\u001b[00m\n",
      "\u001b[1m\u001b[95m \n",
      "[2025-01-08 16:01:29][INFO]: Agent Tom response:\n",
      "\n",
      "Yes, please! Coffee sounds great. Are the pancakes almost ready?\u001b[00m\n",
      "\u001b[1m\u001b[93m \n",
      "[2025-01-08 16:01:31][INFO]: handoff from Tom to Alice by using auto mode\u001b[00m\n",
      "\u001b[1m\u001b[92m \n",
      "[2025-01-08 16:01:32][INFO]: Calling OpenAI agent [Alice]\u001b[00m\n",
      "\u001b[1m\u001b[95m \n",
      "[2025-01-08 16:01:33][INFO]: Agent Alice response:\n",
      "\n",
      "Yes, the pancakes are nearly ready! Just a few more minutes. Do you want them with syrup or fruit?\u001b[00m\n",
      "\u001b[1m\u001b[93m \n",
      "[2025-01-08 16:01:37][INFO]: handoff from Alice to Jerry by using auto mode\u001b[00m\n",
      "\u001b[1m\u001b[92m \n",
      "[2025-01-08 16:01:37][INFO]: Calling OpenAI agent [Jerry]\u001b[00m\n",
      "\u001b[1m\u001b[95m \n",
      "[2025-01-08 16:01:38][INFO]: Agent Jerry response:\n",
      "\n",
      "Mom, can I have syrup on my pancakes, please?\u001b[00m\n",
      "\u001b[1m\u001b[93m \n",
      "[2025-01-08 16:01:40][INFO]: handoff from Jerry to Alice by using auto mode\u001b[00m\n",
      "\u001b[1m\u001b[92m \n",
      "[2025-01-08 16:01:40][INFO]: Calling OpenAI agent [Alice]\u001b[00m\n",
      "\u001b[1m\u001b[95m \n",
      "[2025-01-08 16:01:41][INFO]: Agent Alice response:\n",
      "\n",
      "Almost done with the pancakes! I'll put syrup on yours, Jerry. Tom, I’ll make your coffee right after.\u001b[00m\n",
      "\u001b[1m\u001b[93m \n",
      "[2025-01-08 16:01:42][INFO]: handoff from Alice to Jerry by using auto mode\u001b[00m\n",
      "\u001b[1m\u001b[92m \n",
      "[2025-01-08 16:01:43][INFO]: Calling OpenAI agent [Jerry]\u001b[00m\n",
      "\u001b[1m\u001b[95m \n",
      "[2025-01-08 16:01:44][INFO]: Agent Jerry response:\n",
      "\n",
      "Thanks, Mom! I can't wait for breakfast!\u001b[00m\n",
      "\u001b[1m\u001b[93m \n",
      "[2025-01-08 16:01:45][INFO]: handoff from Jerry to Alice by using auto mode\u001b[00m\n",
      "\u001b[1m\u001b[92m \n",
      "[2025-01-08 16:01:46][INFO]: Calling OpenAI agent [Alice]\u001b[00m\n",
      "\u001b[1m\u001b[95m \n",
      "[2025-01-08 16:01:47][INFO]: Agent Alice response:\n",
      "\n",
      "Tom, your coffee will be ready soon! Just a little longer.\u001b[00m\n",
      "\u001b[1m\u001b[93m \n",
      "[2025-01-08 16:01:48][INFO]: handoff from Alice to Tom by using auto mode\u001b[00m\n",
      "\u001b[1m\u001b[92m \n",
      "[2025-01-08 16:01:49][INFO]: Calling OpenAI agent [Tom]\u001b[00m\n",
      "\u001b[1m\u001b[95m \n",
      "[2025-01-08 16:01:50][INFO]: Agent Tom response:\n",
      "\n",
      "Sounds great, Alice! I’m looking forward to that coffee and the pancakes. Thanks for making breakfast!\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-01-08 16:01:50][INFO]: User input (talk): Make an effort to conclude the conversation gracefully within the next two exchanges, avoiding any further questions or prompts.\u001b[00m\n",
      "\u001b[1m\u001b[93m \n",
      "[2025-01-08 16:01:51][INFO]: handoff from Tom to Alice by using auto mode\u001b[00m\n",
      "\u001b[1m\u001b[92m \n",
      "[2025-01-08 16:01:53][INFO]: Calling OpenAI agent [Alice]\u001b[00m\n",
      "\u001b[1m\u001b[95m \n",
      "[2025-01-08 16:01:59][INFO]: Agent Alice response:\n",
      "\n",
      "I'm glad you appreciate it, Tom! Breakfast will be ready soon for all of us to enjoy together.\u001b[00m\n",
      "\u001b[1m\u001b[93m \n",
      "[2025-01-08 16:01:59][INFO]: handoff from Alice to Jerry by using auto mode\u001b[00m\n",
      "\u001b[1m\u001b[92m \n",
      "[2025-01-08 16:02:00][INFO]: Calling OpenAI agent [Jerry]\u001b[00m\n",
      "\u001b[1m\u001b[95m \n",
      "[2025-01-08 16:02:02][INFO]: Agent Jerry response:\n",
      "\n",
      "That sounds yummy, Mom! I can’t wait to eat breakfast with everyone.\u001b[00m\n"
     ]
    }
   ],
   "source": [
    "g.dialogue(max_turns=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94m \n",
      "[2025-01-08 16:02:09][INFO]: User input (talk): now the dog Spike is barking, what will happen next?\u001b[00m\n",
      "\u001b[1m\u001b[93m \n",
      "[2025-01-08 16:02:10][INFO]: handoff from Jerry to Spike by using auto mode\u001b[00m\n",
      "\u001b[1m\u001b[92m \n",
      "[2025-01-08 16:02:11][INFO]: Calling OpenAI agent [Spike]\u001b[00m\n",
      "\u001b[1m\u001b[95m \n",
      "[2025-01-08 16:02:12][INFO]: Agent Spike response:\n",
      "\n",
      "Woof woof! I smell something tasty! Bark bark! Can we eat now? Woof!\u001b[00m\n",
      "\u001b[1m\u001b[93m \n",
      "[2025-01-08 16:02:13][INFO]: handoff from Spike to Alice by using auto mode\u001b[00m\n",
      "\u001b[1m\u001b[92m \n",
      "[2025-01-08 16:02:14][INFO]: Calling OpenAI agent [Alice]\u001b[00m\n",
      "\u001b[1m\u001b[95m \n",
      "[2025-01-08 16:02:15][INFO]: Agent Alice response:\n",
      "\n",
      "Yes, Spike! Breakfast will be ready soon. Just a little bit longer!\u001b[00m\n",
      "\u001b[1m\u001b[93m \n",
      "[2025-01-08 16:02:17][INFO]: handoff from Alice to Jerry by using auto mode\u001b[00m\n",
      "\u001b[1m\u001b[92m \n",
      "[2025-01-08 16:02:18][INFO]: Calling OpenAI agent [Jerry]\u001b[00m\n",
      "\u001b[1m\u001b[95m \n",
      "[2025-01-08 16:02:19][INFO]: Agent Jerry response:\n",
      "\n",
      "Can I help with breakfast, Mom? I'm really hungry!\u001b[00m\n",
      "\u001b[1m\u001b[93m \n",
      "[2025-01-08 16:02:21][INFO]: handoff from Jerry to Alice by using auto mode\u001b[00m\n",
      "\u001b[1m\u001b[92m \n",
      "[2025-01-08 16:02:21][INFO]: Calling OpenAI agent [Alice]\u001b[00m\n",
      "\u001b[1m\u001b[95m \n",
      "[2025-01-08 16:02:23][INFO]: Agent Alice response:\n",
      "\n",
      "Thank you, Jerry! You can set the table for us while I finish cooking.\u001b[00m\n",
      "\u001b[1m\u001b[93m \n",
      "[2025-01-08 16:02:24][INFO]: handoff from Alice to Jerry by using auto mode\u001b[00m\n",
      "\u001b[1m\u001b[92m \n",
      "[2025-01-08 16:02:25][INFO]: Calling OpenAI agent [Jerry]\u001b[00m\n",
      "\u001b[1m\u001b[95m \n",
      "[2025-01-08 16:02:26][INFO]: Agent Jerry response:\n",
      "\n",
      "Okay, Mom! I'll get the plates and forks for everyone. \u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-01-08 16:02:26][INFO]: User input (talk): Make an effort to conclude the conversation gracefully within the next two exchanges, avoiding any further questions or prompts.\u001b[00m\n",
      "\u001b[1m\u001b[93m \n",
      "[2025-01-08 16:02:27][INFO]: handoff from Jerry to Tom by using auto mode\u001b[00m\n",
      "\u001b[1m\u001b[92m \n",
      "[2025-01-08 16:02:28][INFO]: Calling OpenAI agent [Tom]\u001b[00m\n",
      "\u001b[1m\u001b[95m \n",
      "[2025-01-08 16:02:29][INFO]: Agent Tom response:\n",
      "\n",
      "Great job, Jerry! I appreciate your help. Breakfast will be ready soon, and we can all eat together.\u001b[00m\n",
      "\u001b[1m\u001b[93m \n",
      "[2025-01-08 16:02:30][INFO]: handoff from Tom to Jerry by using auto mode\u001b[00m\n",
      "\u001b[1m\u001b[92m \n",
      "[2025-01-08 16:02:31][INFO]: Calling OpenAI agent [Jerry]\u001b[00m\n",
      "\u001b[1m\u001b[95m \n",
      "[2025-01-08 16:02:32][INFO]: Agent Jerry response:\n",
      "\n",
      "Thanks, Dad! I can't wait to eat together.\u001b[00m\n"
     ]
    }
   ],
   "source": [
    "g.user_input(\"now the dog Spike is barking, what will happen next?\")\n",
    "g.dialogue(max_turns=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[93m \n",
      "[2025-01-08 16:02:41][INFO]: All agents are fully connected\u001b[00m\n",
      "\u001b[1m\u001b[93m \n",
      "[2025-01-08 16:02:41][INFO]: Successfully delete member Tom\u001b[00m\n",
      "\u001b[1m\u001b[93m \n",
      "[2025-01-08 16:02:41][INFO]: \n",
      "Takeaway for Tom:\n",
      "Good morning! Alice asked me about the newspaper. I told her it had some interesting articles and asked how breakfast was coming along. She said she was making pancakes and eggs and offered me coffee. I gladly accepted and asked about the pancakes. Jerry chimed in, asking for syrup on his pancakes. Alice assured us that breakfast was nearly ready. I thanked her for making breakfast and looked forward to it. Then Spike started barking about the tasty smell. Alice packed up everything, and Jerry offered to help by setting the table. I praised Jerry for his help. Soon, we would all be eating breakfast together, and I was really looking forward to the family time.\u001b[00m\n",
      "\u001b[1m\u001b[93m \n",
      "[2025-01-08 16:02:43][INFO]: All agents are fully connected\u001b[00m\n",
      "\u001b[1m\u001b[93m \n",
      "[2025-01-08 16:02:43][INFO]: Successfully delete member Alice\u001b[00m\n",
      "\u001b[1m\u001b[93m \n",
      "[2025-01-08 16:02:43][INFO]: \n",
      "Takeaway for Alice:\n",
      "I woke up early and started making breakfast. I chatted with Tom about the newspaper while cooking. I prepared pancakes and eggs and asked if he wanted coffee. Jerry joined in and asked for syrup on his pancakes. I reassured both of them that breakfast was almost ready. Spike barked as he smelled the food. I encouraged him to wait a little longer. Jerry offered to help, and I asked him to set the table. Tom praised Jerry for his help. Everyone was excited to eat breakfast together.\u001b[00m\n",
      "\u001b[1m\u001b[93m \n",
      "[2025-01-08 16:02:45][INFO]: All agents are fully connected\u001b[00m\n",
      "\u001b[1m\u001b[93m \n",
      "[2025-01-08 16:02:45][INFO]: current agent Jerry is deleted, randomly select Spike as the new current agent\u001b[00m\n",
      "\u001b[1m\u001b[93m \n",
      "[2025-01-08 16:02:45][INFO]: Successfully delete member Jerry\u001b[00m\n",
      "\u001b[1m\u001b[93m \n",
      "[2025-01-08 16:02:45][INFO]: \n",
      "Takeaway for Jerry:\n",
      "Good morning! Mom is making breakfast. Dad checks the newspaper and talks to Mom. I asked Mom for syrup on my pancakes. Mom said they are almost done and she will put syrup on mine. I can't wait for breakfast! Spike is barking because he smells something tasty. Mom tells him breakfast will be ready soon. I offered to help, and Mom said I can set the table. I'm getting the plates and forks. Dad appreciates my help, and I am excited to eat together.\u001b[00m\n",
      "\u001b[1m\u001b[93m \n",
      "[2025-01-08 16:02:47][INFO]: All agents are fully connected\u001b[00m\n",
      "\u001b[1m\u001b[93m \n",
      "[2025-01-08 16:02:47][INFO]: current agent Spike is deleted, randomly select None as the new current agent\u001b[00m\n",
      "\u001b[1m\u001b[93m \n",
      "[2025-01-08 16:02:47][INFO]: Successfully delete member Spike\u001b[00m\n",
      "\u001b[1m\u001b[93m \n",
      "[2025-01-08 16:02:47][INFO]: \n",
      "Takeaway for Spike:\n",
      "This morning, I woke up early and smelled something delicious. I heard my human, Alice, talking to Tom about breakfast. I barked happily, wanting to eat. I found out they were making pancakes and eggs, and I got excited! Alice told me breakfast would be ready soon. Jerry wanted to help, and I liked that he was getting the table ready. Everyone seemed happy, and I couldn’t wait to enjoy the meal with my family. Woof woof!\u001b[00m\n"
     ]
    }
   ],
   "source": [
    "g.dismiss_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "del g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
