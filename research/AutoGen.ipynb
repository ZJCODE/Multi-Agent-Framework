{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoGen\n",
    "\n",
    "A framework for building AI agents and applications\n",
    "\n",
    "https://microsoft.github.io/autogen/stable/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install -U \"autogen-agentchat\" \"autogen-ext[openai]\"\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, content=\"Say 'Hello World!'\", type='TextMessage'), TextMessage(source='assistant', models_usage=RequestUsage(prompt_tokens=41, completion_tokens=3), content='Hello World!', type='TextMessage')], stop_reason=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = AssistantAgent(\"assistant\", OpenAIChatCompletionClient(model=\"gpt-4o-mini\"))\n",
    "await agent.run(task=\"Say 'Hello World!'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quickstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "hangzhou\n",
      "---------- weather_agent ----------\n",
      "[FunctionCall(id='call_T4UV6X7aSCzFA5TSPF4cCB4A', arguments='{\"city\":\"Hangzhou\"}', name='get_weather')]\n",
      "---------- weather_agent ----------\n",
      "[FunctionExecutionResult(content='The weather in Hangzhou is 73 degrees and Sunny.', call_id='call_T4UV6X7aSCzFA5TSPF4cCB4A')]\n",
      "---------- weather_agent ----------\n",
      "The weather in Hangzhou is 73 degrees and Sunny.\n"
     ]
    }
   ],
   "source": [
    "# Define a tool\n",
    "async def get_weather(city: str) -> str:\n",
    "    return f\"The weather in {city} is 73 degrees and Sunny.\"\n",
    "\n",
    "# Define an agent\n",
    "weather_agent = AssistantAgent(\n",
    "    name=\"weather_agent\",\n",
    "    model_client=OpenAIChatCompletionClient(model=\"gpt-4o-mini\"),\n",
    "    tools=[get_weather],\n",
    ")\n",
    "\n",
    "# Define a team with a single agent and maximum auto-gen turns of 1.\n",
    "agent_team = RoundRobinGroupChat([weather_agent], max_turns=1)\n",
    "\n",
    "while True:\n",
    "    # Get user input from the console.\n",
    "    user_input = input(\"Enter a message (type 'exit' to leave): \")\n",
    "    if user_input.strip().lower() == \"exit\":\n",
    "        break\n",
    "    # Run the team and stream messages to the console.\n",
    "    stream = agent_team.run_stream(task=user_input)\n",
    "    await Console(stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish_reason='unknown' content='The capital of France is Paris.' usage=RequestUsage(prompt_tokens=15, completion_tokens=7) cached=False logprobs=None\n"
     ]
    }
   ],
   "source": [
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_core.models import UserMessage\n",
    "\n",
    "openai_model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\")\n",
    "result = await openai_model_client.create([UserMessage(content=\"What is the capital of France?\", source=\"user\")])\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Types of Messages\n",
    "\n",
    "At a high level, messages in AgentChat can be categorized into two types: agent-agent messages and an agentâ€™s internal events and messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextMessage(source='User', models_usage=None, content='Hello, world!', type='TextMessage')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogen_agentchat.messages import TextMessage\n",
    "\n",
    "text_message = TextMessage(content=\"Hello, world!\", source=\"User\")\n",
    "\n",
    "text_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiModalMessage(source='User', models_usage=None, content=['Can you describe the content of this image?', <autogen_core._image.Image object at 0x1166120d0>], type='MultiModalMessage')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from io import BytesIO\n",
    "\n",
    "import requests\n",
    "from autogen_agentchat.messages import MultiModalMessage\n",
    "from autogen_core import Image as AGImage\n",
    "from PIL import Image\n",
    "\n",
    "pil_image = Image.open(BytesIO(requests.get(\"https://picsum.photos/300/200\").content))\n",
    "img = AGImage(pil_image)\n",
    "multi_modal_message = MultiModalMessage(content=[\"Can you describe the content of this image?\", img], source=\"User\")\n",
    "\n",
    "multi_modal_message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_core import CancellationToken\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "\n",
    "\n",
    "# Define a tool that searches the web for information.\n",
    "async def web_search(query: str) -> str:\n",
    "    \"\"\"Find information on the web\"\"\"\n",
    "    return \"AutoGen is a programming framework for building multi-agent applications.\"\n",
    "\n",
    "\n",
    "# Create an agent that uses the OpenAI GPT-4o model.\n",
    "model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\")\n",
    "agent = AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    model_client=model_client,\n",
    "    tools=[web_search],\n",
    "    system_message=\"Use tools to solve tasks.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inner Messages:\n",
      "[ToolCallRequestEvent(source='assistant', models_usage=RequestUsage(prompt_tokens=61, completion_tokens=15), content=[FunctionCall(id='call_kQLUCGml2bo0NHqYzF7AwTTJ', arguments='{\"query\":\"AutoGen\"}', name='web_search')], type='ToolCallRequestEvent'), ToolCallExecutionEvent(source='assistant', models_usage=None, content=[FunctionExecutionResult(content='AutoGen is a programming framework for building multi-agent applications.', call_id='call_kQLUCGml2bo0NHqYzF7AwTTJ')], type='ToolCallExecutionEvent')]\n",
      "Chat Message:\n",
      "source='assistant' models_usage=None content='AutoGen is a programming framework for building multi-agent applications.' type='ToolCallSummaryMessage'\n"
     ]
    }
   ],
   "source": [
    "response = await agent.on_messages(\n",
    "    [TextMessage(content=\"Find information on AutoGen\", source=\"user\")],\n",
    "    cancellation_token=CancellationToken(),\n",
    ")\n",
    "\n",
    "print(\"Inner Messages:\")\n",
    "print(response.inner_messages)\n",
    "print(\"Chat Message:\")\n",
    "print(response.chat_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- assistant ----------\n",
      "[FunctionCall(id='call_JWGi96gtQlaQMfXSyzBiyRGl', arguments='{\"query\":\"AutoGen framework multi-agent applications\"}', name='web_search')]\n",
      "---------- assistant ----------\n",
      "[FunctionExecutionResult(content='AutoGen is a programming framework for building multi-agent applications.', call_id='call_JWGi96gtQlaQMfXSyzBiyRGl')]\n",
      "---------- assistant ----------\n",
      "AutoGen is a programming framework for building multi-agent applications.\n"
     ]
    }
   ],
   "source": [
    "response = await Console(\n",
    "    agent.on_messages_stream(\n",
    "        [TextMessage(content=\"Find information on AutoGen\", source=\"user\")],\n",
    "        cancellation_token=CancellationToken(),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source='assistant' models_usage=RequestUsage(prompt_tokens=159, completion_tokens=15) content=[FunctionCall(id='call_EKx3hTTosyvbd9AwidzR8fLw', arguments='{\"query\":\"AutoGen\"}', name='web_search')] type='ToolCallRequestEvent'\n",
      "source='assistant' models_usage=None content=[FunctionExecutionResult(content='AutoGen is a programming framework for building multi-agent applications.', call_id='call_EKx3hTTosyvbd9AwidzR8fLw')] type='ToolCallExecutionEvent'\n",
      "Response(chat_message=ToolCallSummaryMessage(source='assistant', models_usage=None, content='AutoGen is a programming framework for building multi-agent applications.', type='ToolCallSummaryMessage'), inner_messages=[ToolCallRequestEvent(source='assistant', models_usage=RequestUsage(prompt_tokens=159, completion_tokens=15), content=[FunctionCall(id='call_EKx3hTTosyvbd9AwidzR8fLw', arguments='{\"query\":\"AutoGen\"}', name='web_search')], type='ToolCallRequestEvent'), ToolCallExecutionEvent(source='assistant', models_usage=None, content=[FunctionExecutionResult(content='AutoGen is a programming framework for building multi-agent applications.', call_id='call_EKx3hTTosyvbd9AwidzR8fLw')], type='ToolCallExecutionEvent')])\n"
     ]
    }
   ],
   "source": [
    "async for response in agent.on_messages_stream(\n",
    "    [TextMessage(content=\"Find information on AutoGen\", source=\"user\")],\n",
    "    cancellation_token=CancellationToken(),\n",
    "):\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from autogen_ext.tools.langchain import LangChainToolAdapter\n",
    "from langchain_experimental.tools.python.tool import PythonAstREPLTool\n",
    "\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/pandas-dev/pandas/main/doc/data/titanic.csv\")\n",
    "tool = LangChainToolAdapter(PythonAstREPLTool(locals={\"df\": df}))\n",
    "model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\")\n",
    "agent = AssistantAgent(\n",
    "    \"assistant\", tools=[tool], model_client=model_client, \n",
    "    system_message=f\"Use the `df` variable to access the dataset,column names are {df.columns}.\",\n",
    "    reflect_on_tool_use=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(chat_message=TextMessage(source='assistant', models_usage=RequestUsage(prompt_tokens=772, completion_tokens=15), content='The average age of the passengers is approximately 29.7 years.', type='TextMessage'), inner_messages=[])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await Console(\n",
    "    agent.on_messages_stream(\n",
    "        [TextMessage(content=\"What's the average age of the passengers?\", source=\"user\")], CancellationToken()\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(chat_message=TextMessage(source='assistant', models_usage=RequestUsage(prompt_tokens=592, completion_tokens=47), content='The average age of all survivors is approximately 28.3 years.\\n\\nWhen broken down by gender:\\n- Average age of female survivors: approximately 28.8 years\\n- Average age of male survivors: approximately 27.3 years', type='TextMessage'), inner_messages=[ToolCallRequestEvent(source='assistant', models_usage=RequestUsage(prompt_tokens=543, completion_tokens=81), content=[FunctionCall(id='call_WRiHoJyUg9s33RMcKjYg3G1t', arguments='{\"query\": \"df[df[\\'Survived\\'] == 1][\\'Age\\'].mean()\"}', name='python_repl_ast'), FunctionCall(id='call_YnEbXIjD57CCC4ZICKekFG01', arguments='{\"query\": \"df[df[\\'Survived\\'] == 1].groupby(\\'Sex\\')[\\'Age\\'].mean()\"}', name='python_repl_ast')], type='ToolCallRequestEvent'), ToolCallExecutionEvent(source='assistant', models_usage=None, content=[FunctionExecutionResult(content='28.343689655172415', call_id='call_WRiHoJyUg9s33RMcKjYg3G1t'), FunctionExecutionResult(content='Sex\\nfemale    28.847716\\nmale      27.276022\\nName: Age, dtype: float64', call_id='call_YnEbXIjD57CCC4ZICKekFG01')], type='ToolCallExecutionEvent')])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await Console(\n",
    "    agent.on_messages_stream(\n",
    "        [TextMessage(content=\"What is the average age of survivors? Please display the results for all genders as well as separately for each gender.\", source=\"user\")], CancellationToken()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
